# List of resources related to topics of AI/ML and Deep Learning specifically

# Useful sites #

| Name | Comment |
| --- | --- |
| [arXiv by Cornell University](https://arxiv.org/) | All  AI/ML/DL papers appear hear |
| [arXiv - Source code for papers](http://www.gitxiv.com/) | Source for published arXiv papers |
| [arXiv Chrome extension](https://fermatslibrary.com/librarian) | Display arXiv paper related information |
| [Search and track arXiv AI/ML/DL related papers](http://www.arxiv-sanity.com/) | Search and track on top of arXiv by Andrej Karpathy |
| [Papers with code](https://github.com/zziz/pwc) | Popular papers with implementation - sorted by year | 
| [Mendeley Desktop](https://www.mendeley.com/downloads) | Manage reading list of papers | 
| [Reddit ML forum](https://www.reddit.com/r/MachineLearning/) | AI/ML subforum |
| [DataTau forum](http://www.datatau.com/) | AI/ML dedicated forum |
| [Measuring the Progress of AI Research](https://www.eff.org/ai/metrics) | Comprehensive dataset of AI topics and advances within them |
| [State of the Art results in different domain](https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems) | Github repo to papers and results with SotA results |
| [The Neural Network Zoo](http://www.asimovinstitute.org/neural-network-zoo/) | Chart and high-level overview of different Neural Networks |
| [Guide to Machine Learning by Yerevann](http://yerevann.com/a-guide-to-deep-learning/) | Very good collection of materials for different topics |
| [A Tour of Machine Learning Algorithms](http://machinelearningmastery.com/a-tour-of-machine-learning-algorithms/) | Overview of ML algorithms |
| [AI/ML cheat sheet](https://github.com/kailashahirwar/cheatsheets-ai) | Constantly updated |
| [Machine Learning cheat sheet wiki](https://ml-cheatsheet.readthedocs.io/en/latest/) | Lots of starter information |
| [Deep Learning tutorial by Stanford](http://ufldl.stanford.edu/tutorial/) | Very good material explaining different topics |
| [Machine Learning, Deep Learning and other tutorials](https://unsupervisedmethods.com/over-150-of-the-best-machine-learning-nlp-and-python-tutorials-ive-found-ffce2939bd78) | Lots of information, but not organized very well |
| [Kaggle past solutions](http://ndres.me/kaggle-past-solutions/) | Good collection, but still missing many entries |
| [List of pre-trained models](https://github.com/GalacticExchange/pretrained) | Pre-trained models for TensorFlow, PyTorch |
| [Deep Learning Architecture Genealogy](https://github.com/hunkim/deep_architecture_genealogy) | Mindmap |

# Newsletters and podcasts #

| Name | Comment |
| --- | --- |
| [Deep Learning Weekly](http://www.deeplearningweekly.com/) | Weekly newsletter (Deep Learning) |
| [Transmission](http://transmission.ai/) | Weekly newsletter (Deep Learning, Self-driving cars) |
| [The Wild Week in AI](https://www.getrevue.co/profile/wildml) | Weekly newsletter (AI, Deep Learning) |
| [Artificial Intelligence and Deep Learning Weekly](http://aidl.io) | Weekly newsletter (AI, Deep Learning) |
| [City AI](https://www.getrevue.co/profile/CityAI) | Monthly newsletter (AI) |
| [Linear Digressions podcast](http://lineardigressions.com/) | Weekly ML/data science podcast |
| [This Week in Machine Learning](http://blog.udacity.com/this-week-machine-learning) | Weekly news on ML from Udacity |
| [Partially Derivative podcast](http://partiallyderivative.com/) | Weekly news |
| [This Week in Machine Learning & AI podcast](https://twimlai.com/) | |
| [Data Sceptic podcast](https://dataskeptic.com/) | |
| [SDS podcast](https://www.superdatascience.com/podcast/) | Data science focused podcast |
| [Talking Machines podcast](http://www.thetalkingmachines.com/) | |
| [The AI podcast](https://soundcloud.com/theaipodcast) | |
| [O'Reilly Data Show podcast](https://www.oreilly.com/topics/oreilly-data-show-podcast) | | 
| [O'Reilly Bots podcast](https://www.oreilly.com/topics/oreilly-bots-podcast) | |
| [Data Stories podcast](http://datastori.es/) | |
| [Learning Machines 101 podcast](http://www.learningmachines101.com/) | |
| [Data Driven podcast](http://datadriven.tv/) | |

# Books #
[Deep Learning (Adaptive Computation and Machine Learning series)](http://www.deeplearningbook.org/), [Github](https://github.com/HFTrader/DeepLearningBook), [Amazon](https://www.amazon.com/Deep-Learning-Adaptive-Computation-Machine/dp/0262035618/) and its translation [ГЛУБОКОЕ ОБУЧЕНИЕ](http://dmkpress.com/catalog/computer/data/978-5-97060-554-7/) <br>
[Grokking Deep Learning](https://www.manning.com/books/grokking-deep-learning) <br>
[Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/) <br>
[Machine Learning A Probabilistic Perspective](https://mitpress.mit.edu/books/machine-learning-0) <br>
[Artificial Inteligence](https://www.gitbook.com/book/leonardoaraujosantos/artificial-inteligence/details) <br>
[Machine Learning Yearning by Andrew Ng](http://www.mlyearning.org/) <br>
[Python Deep Learning](https://www.amazon.com/Python-Deep-Learning-Valentino-Zocca/dp/1786464454/), [Packtpub](https://www.packtpub.com/big-data-and-business-intelligence/python-deep-learning) <br>
[Information Theory, Inference and Learning Algorithms](http://www.inference.org.uk/itila/), [Amazon](https://www.amazon.com/Information-Theory-Inference-Learning-Algorithms/dp/0521642981/) <br>
[Understanding Machine Learning: From Theory to Algorithms](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/) <br>
[All of Statistics: A Concise Course in Statistical Inference (Springer Texts in Statistics) ](https://www.amazon.com/All-Statistics-Statistical-Inference-Springer/dp/0387402721) <br>

# GPU servers hosting #

| Service | Details |
| --- | --- |
| [Google Colabotory](https://colab.research.google.com) | Free GPU server for AI tasks |
| [Crestle](https://www.crestle.com/) | Per second pricing, switch between CPU/GPU |
| [Paperspace](https://www.paperspace.com) | Very good pricing, V100, 16/24GB GPU options |
| [FloydHub](https://www.floydhub.com) | Per second pricing, quick launch, competitive prices |
| [AWS P3 Spot instances](http://wiki.fast.ai/index.php/AWS_Spot_instances) | Usual AWS P2 pricing is insane, but you could get Spot instances cheaper. <br> [How to setup](https://blog.slavv.com/learning-machine-learning-on-the-cheap-persistent-aws-spot-instances-668e7294b6d8) |
| [Google Cloud GPU](https://cloud.google.com/free/) | $300 free credit to spend <br> [How to setup](https://medium.com/google-cloud/jupyter-tensorflow-nvidia-gpu-docker-google-compute-engine-4a146f085f17) |
| [Hetzner dedicated 1080 GPU server](https://www.hetzner.com/dedicated-rootserver/ex51-ssd-gpu) | Intel i7-6700/64GB RAM/2x500GB SSD/GeForce GTX 1080 = 99 EUR month + 99 EUR setup fee. |
| [Google Cloud TPU](https://cloud.google.com/tpu/) | Still Alpha - pricign and availability unknown |

# Benchmarking #
[Baidu DL hardware benchmarks](https://github.com/baidu-research/DeepBench) Benchmarking of different DL algorithms on different hardware <br>
[Benchmarks of convnets](https://github.com/soumith/convnet-benchmarks) Outdatd for major convnets, but have Nervana results <br>
[Benchmarks for popular CNN models](https://github.com/jcjohnson/cnn-benchmarks) <br>
[Benchmarking TensorFlow on Cloud CPUs: Cheaper Deep Learning than Cloud GPUs](http://minimaxir.com/2017/07/cpu-or-gpu/) <br>
[Github Repository to benchmark the performance of Cloud CPUs vs. Cloud GPUs on TensorFlow and Google Compute Engine](https://github.com/minimaxir/deep-learning-cpu-gpu-benchmark) <br>
[Benchmarking State-of-the-Art Deep Learning Software Tools](http://dlbench.comp.hkbu.edu.hk/) and [Github](https://github.com/hclhkbu/dlbench) <br>

# Simulation frameworks #
| Name | Details |
| --- | --- |
| [DeepMind Lab](https://github.com/deepmind/lab) | A customisable 3D platform for agent-based AI research |
| [OpenAI Universe](https://universe.openai.com/) | A software platform for evaluating and training intelligent agents across the world’s supply of games, websites and other applications. |
| [OpenAI Gym](https://gym.openai.com/) | A toolkit for developing and comparing reinforcement learning algorithms |
| [OpenAI RoboSchool](https://github.com/openai/roboschool) | Open-source software for robot simulation, integrated with OpenAI Gym |
| [Udacity car sim](https://github.com/udacity/self-driving-car-sim) | A self-driving car simulator built with Unity  |
| [Microsoft AirSim](https://github.com/Microsoft/AirSim) | AirSim is a simulator for drones |
| [Facebook ELF](https://github.com/facebookresearch/ELF) | An Extensive, Lightweight and Flexible Research Platform for Real-time Strategy Games <br> [Intro] (https://code.facebook.com/posts/132985767285406/introducing-elf-an-extensive-lightweight-and-flexible-platform-for-game-research/) |
| [TorchCraft](https://github.com/TorchCraft/TorchCraft) | Connecting Torch to StarCraft |
| [Facebook ParlAI](https://github.com/facebookresearch/ParlAI) | A framework for training and evaluating AI models on a variety of openly available dialog datasets |
| [OpenAI RLLab](https://github.com/openai/rllab) | Framework for developing and evaluating reinforcement learning algorithms, fully compatible with OpenAI Gym |
| [Baidu Apollo](https://github.com/ApolloAuto/apollo) | An open autonomous driving platform |
| [Carla car simulator](http://carla.org/) | CARLA is an open-source simulator for autonomous driving research |
| [ChosunTruck](https://github.com/bethesirius/ChosunTruck) | Euro Truck Simulator 2 autonomous driving solution |

# Frameworks #

| Name | Language | Comment |
| --- | --- | --- |
| [TensorFlow](https://www.tensorflow.org/) | Python | Nobody ever got fired for choosing TensorFlow |
| [Keras](https://keras.io/) | Python | High-level library on top of TensorFlow, CNTK, Theano |
| [PyTorch](http://pytorch.org/) | Python | [Intro in 10 minutes](https://hsaghir.github.io/data_science/pytorch_starter/) |
| [Theano](http://www.deeplearning.net/software/theano/) | Python | |
| [Caffe](http://caffe.berkeleyvision.org/) | C++ | |
| [CNTK](http://cntk.ai/) | C++ | The Microsoft Cognitive Toolkit |
| [Sonnet](https://github.com/deepmind/sonnet) | Python | High-level library on top of TF by DeepMind |
| [Nnabla](https://nnabla.org/) | C++ | Neural Network Libraries by Sony |
| [Core ML](https://developer.apple.com/documentation/coreml) | ? | Apple OS only |
| [ELL](https://github.com/Microsoft/ELL) | C++ | Microsoft Embedded Learning Library - Machine Learning on mini devices like Raspberry Pi |
| [WebDNN](https://mil-tokyo.github.io/webdnn/) | Javascript | Optimized Web framework for running DNN |
| [DeepLearn.js](https://pair-code.github.io/deeplearnjs/) | Javascript | Google take on DL library in Javascript |
| [Intel Nervana](https://github.com/NervanaSystems/neon) | Python/C++ | Intel CPU optimized MKL framework |
| [LightGBM](https://github.com/Microsoft/LightGBM) | C++ | Microsoft A fast, distributed, high performance gradient boosting (GBDT, GBRT, GBM or MART) framework based on decision tree algorithms |
| [OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) | C++ | A Real-Time Multi-Person Keypoint Detection And Multi-Threading C++ Library |
| [Polyaxon](https://github.com/polyaxon/polyaxon) | Python | A platform that helps you build, manage and monitor deep learning models |

# Math preparation #
Start with watching awesome [MIT Linear Algebra course](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/) via [Youtube playlist](https://www.youtube.com/playlist?list=PLE7DDD91010BC51F8) - first 10 or so lectures would be enough for some time. <br>
[Linear algebra in 4 pages](https://minireference.com/static/tutorials/linear_algebra_in_4_pages.pdf) <br>
And only then start reading books, if you need more content - good summary of Linear Algebra from Deep Learning book [Chapter 2](http://www.deeplearningbook.org/contents/linear_algebra.html) <br>
[Common Probability Distributions: The Data Scientist’s Crib Sheet](https://blog.cloudera.com/blog/2015/12/common-probability-distributions-the-data-scientists-crib-sheet/) <br>
[Math probability cheat sheet](http://www.wzchen.com/s/probability_cheatsheet.pdf) <br>
[Statistics cheat sheet](http://web.mit.edu/~csvoss/Public/usabo/stats_handout.pdf) <br>
[Calculus cheat sheet](http://tutorial.math.lamar.edu/getfile.aspx?file=B,41,N) <br>
[Matrix Cookbook](http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3274/pdf/imm3274.pdf) <br>
[The Mathematics of Machine Learning](http://datascience.ibm.com/blog/the-mathematics-of-machine-learning/) <br>

# Online courses #

| Name | Link | Rating | Comment |
| --- | --- | --- | --- |
| Neural Networks Demystified | [Youtube playlist](https://www.youtube.com/playlist?list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU) | :star::star::star::star: | Good intro to neural networks - heavy on math, uses Python code |
| Stanford CS231n: Convolutional Neural Networks for Visual Recognition | [Official page](http://cs231n.stanford.edu/) <br> [Github](https://cs231n.github.io/) <br> [Youtube 2016 playlist](https://www.youtube.com/playlist?list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC) <br> [Youtube 2017 videos](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)  | :star::star::star::star::star: | Start Deep Learning education from this one - focused on image processing. Many lectures presented by Andrej Karpathy in 2016 videos |
| Udacity Deep Learning Foundation Nanodegree Program | [Official page](https://www.udacity.com/course/deep-learning-nanodegree-foundation--nd101) | :star::star::star::star::star: | $400 for 6 months course - you would need to spend at least 10h a week to complete it. Knowledge of Python 3.x and Numpy would make your life much easier - Pandas would help too. |
| Udacity Intro to Machine Learning | [Official page](https://classroom.udacity.com/courses/ud120) | :star::star::star::star: | Basics of ML - top algorithms, process to work with data, etc. <br> All code done in Python and scikit-learn - majority of test tasks are simple and very similiar |
| Coursera Machine Learning by Andrew Ng | [Official page](https://www.coursera.org/learn/machine-learning) | :star::star::star::star::star: | This course is classics by now - Coursera started from it and its very good at explaining classical ML algorithms. <br> One minor annoynce - tasks are done in Octave, but you could do them in Python using unofficial [Github repo](https://github.com/mstampfer/Coursera-Stanford-ML-Python) |
| Stanford CS224n: Deep Learning for Natural Language Processing | [Official page](https://web.stanford.edu/class/cs224n/) <br> [Youtube playlist](https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6) <br> [PyTorch models implementation](https://github.com/DSKSD/DeepNLP-models-Pytorch) | In Progress | Focus - NLP with Deep Learning. <br> Previously known as [CS224d: Deep Learning for Natural Language Processing](http://cs224d.stanford.edu/) |
| David Silver’s course on reinforcement learning | [Official page](http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Teaching.html) <br> [Youtube playlist](https://www.youtube.com/playlist?list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT) | - | David was main developer of AlphaGo |
| Udacity Reinforcement Learning by Georgia Tech (CS 8803) | [Official page](https://www.udacity.com/course/reinforcement-learning--ud600#) | - | |
| Deep Learning 101 | [Official page](https://cognitiveclass.ai/courses/introduction-deep-learning/) | Skip it | Tries to do overview without providing details - more like DP for non-IT person |
| Deep Learning with TensorFlow | [Official page](https://cognitiveclass.ai/courses/deep-learning-tensorflow/) | Skip it | Very high level with not enough "meat" |
| Tensorflow and deep learning - without a PhD by Martin Görner | [Youtube video](https://www.youtube.com/watch?v=vq2nnJ4g6N0) | :star::star::star: | 2.5h video trying to cover everything in DL area from beginning - IMHO its too shallow |
| MIT 6.S191: Introduction to Deep Learning | [Official page](http://introtodeeplearning.com/) <br> [Youtube playlist](https://www.youtube.com/playlist?list=PLkkuNyzb8LmxFutYuPA7B4oiMn6cjD6Rs) | - | Short intro course |
| Oxford Deep Learning for Natural Language Processing 2017 by Phil Blunsom | [Official page](https://www.cs.ox.ac.uk/teaching/courses/2016-2017/dl/) <br> [Github](https://github.com/oxford-cs-deepnlp-2017/) <br> [Youtube playlist](https://www.youtube.com/playlist?list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm) | - | Main Oxford NLP course | 
| UC Berkeley CS 294: Deep Reinforcement Learning, Fall 2017 | [Official page](http://rll.berkeley.edu/deeprlcourse/) <br> [Youtube playlist](https://www.youtube.com/playlist?list=PLkFD6_40KJIwTmSbCv9OVJB3YaO4sFwkX) | - | |
| MIT 6.S094: Deep Learning for Self-Driving Cars | [Official page](http://selfdrivingcars.mit.edu/) <br> [Youtube playlist](https://www.youtube.com/playlist?list=PLrAXtmErZgOeiKm4sgNOknGvNjby9efdf) | - | |
| Deep Learning for Speech and Language 2017 | [Official page](https://telecombcn-dl.github.io/2017-dlsl/) <br> [Youtube](https://www.youtube.com/playlist?list=PL-5DCZHuHZkWeF9ljIjoC_X5gHRLNtIkU) | - | Only course dedicated to advanced speech recognition using Deep Learning | 
| Fast.ai Practical Deep Learning For Coders, Part 1 | [Official page](http://course.fast.ai/) <br> [Youtube](https://www.youtube.com/playlist?list=PLfYUBJiXbdtS2UQRzyrxmyVHoGW0gmLSM) | - | |
| Fast.ai Practical Deep Learning For Coders, Part 2 | [Official page](http://course.fast.ai/part2.html) <br> [Files](http://files.fast.ai/part2/) | - | |
| Coursera Neural Networks for Machine Learning | [Official page](https://www.coursera.org/learn/neural-networks) | - | This is very very very hard course to master - think twice before taking it ([course review here](http://thegrandjanitor.com/2017/04/10/review-of-hintons-coursera-neural-network-and-machine-learning/)) :) |
| OpenDataScience Machine Learning course | [Official page](https://github.com/Yorko/mlcourse_open) | - | In Russian |
| Yandex Reinforcement learning in the wild | [Official page](https://github.com/yandexdataschool/Practical_RL) | - | Links to video inside Github folders |
| Введение в обработку естественного языка | [Official page](https://stepik.org/course/%D0%92%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5-%D0%B2-%D0%BE%D0%B1%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D1%83-%D0%B5%D1%81%D1%82%D0%B5%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE-%D1%8F%D0%B7%D1%8B%D0%BA%D0%B0-1233) | - | In Russian |
| Introduction to Natural Language Processing | [Official page](https://www.coursera.org/learn/natural-language-processing) | - | |
| Deep learning at Oxford 2015 | [Official page](https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/) <br> [Youtube](https://www.youtube.com/playlist?list=PLE6Wd9FR--EfW8dtjAuPoTuPcqmOV53Fu) | - | |
| Stanford CS 20SI: Tensorflow for Deep Learning Research | [Official page](https://web.stanford.edu/class/cs20si/) <br> [Github](https://github.com/chiphuyen/tf-stanford-tutorials) <br> [Youtube](https://www.youtube.com/watch?v=g-EvyKpZjmQ) | - | TensorFlow learning |
| Udacity Introduction to Computer Vision by Georgia Tech (CS 6476) | [Official page](https://www.udacity.com/course/introduction-to-computer-vision--ud810) | - | |
| Berkeley CS188 Intro to AI | [Official page](http://ai.berkeley.edu/home.html) <br> [Youtube](https://www.youtube.com/watch?feature=player_embedded&v=J6PBD-wNEDs) | - | Introduction to classic AI |
| Hugo Larochelle's Neural Network class | [Official page](http://info.usherbrooke.ca/hlarochelle/neural_networks/content.html) | - | Little outdated now, but still should be great |
| Deep Learning inaugural lectures by Yann LeCun | [Official page](https://www.college-de-france.fr/site/en-yann-lecun/_course.htm) | - | Lectures only |
| Coursera Probabilistic Graphical Models | [Part 1](https://www.coursera.org/learn/probabilistic-graphical-models) <br> [Part 2](https://www.coursera.org/learn/probabilistic-graphical-models-2-inference) <br> [Part 3](https://www.coursera.org/learn/probabilistic-graphical-models-3-learning) | - | More than you want to know in this area - these are very challenging courses |
| Caltech Machine Learning course by Yaser S. Abu-Mostafa | [Official page](https://work.caltech.edu/telecourse.html) <br> [Youtube](https://www.youtube.com/watch?v=mbyG85GZ0PI&hd=1) | - | Also available via edX platform [Learning from Data](https://www.edx.org/course/learning-data-introductory-machine-caltechx-cs1156x-0) |
| Berkeley CS 294-129: Designing, Visualizing and Understanding Deep Neural Networks (2016) | [Official page](https://bcourses.berkeley.edu/courses/1453965) <br> [Youtube](https://www.youtube.com/playlist?list=PLkFD6_40KJIxopmdJF_CLNqG3QuDFHQUm) | - | |
| DEEP LEARNING AND REINFORCEMENT LEARNING SUMMER SCHOOL 2017 | [Official page](https://mila.umontreal.ca/en/cours/deep-learning-summer-school-2017/) <br> [Github](https://github.com/Breakend/RLSSContinuousControlTutorial) | - | Slides only |
| MIT Mathematics of Machine Learning 2015 | [Official page](https://ocw.mit.edu/courses/mathematics/18-657-mathematics-of-machine-learning-fall-2015/index.htm) | - | Slides only |
| Berkeley CS 294-131: Special Topics in Deep Learning | [Official page](https://berkeley-deep-learning.github.io/cs294-131-s17/) | - | Slides only |
| Berkeley STAT212b: Course on Deep Learning for Spring 2016 | [Official page](https://github.com/joanbruna/stat212b) | - | Slides only |

# Python libraries and tools #

| Name | Comment |
| --- | --- |
| [Jupyter notebook](https://jupyter.org) | Use it :) |
| [NumPy](http://www.numpy.org) | Math |
| [SciPy](https://www.scipy.org/scipylib/index.html) | Math |
| [CuPy](https://cupy.chainer.org) | CUDA accelerated Numpy |
| [Pandas](http://pandas.pydata.org) | Data analysis |
| [Scikit](http://scikit-learn.org/stable) | Machine Learning algorithms |
| [matplotlib](https://matplotlib.org) | Data visualization |
| [Seaborn](https://seaborn.pydata.org) | Statistical data visualization |
| [Scikit-plot](https://github.com/reiinakano/scikit-plot) | Add plotting to scikit-learn |
| [keras-vis](https://github.com/raghakot/keras-vis) | Visualization of Keras DL layers |
| [NLTK](http://www.nltk.org) | Natural Language Toolkit |
| [AllenNLP](http://allennlp.org/) | An open-source NLP research library, built on PyTorch |
| [Xcessiv](https://xcessiv.readthedocs.io/en/stable/) | Web-based application for quick and scalable hyperparameter tuning and stacked ensembling |
| [Luigi](https://github.com/spotify/luigi) | Helps you build complex pipelines of batch jobs. It handles dependency resolution, workflow management, visualization etc |
| [Taggy.ai](https://taggy.ai/#/) | Helps you tag image datasets |
| [Hyperopt](https://github.com/hyperopt/hyperopt) | Distributed Asynchronous Hyper-parameter Optimization |

# TensorFlow & Co #
[TensorFlow Playground](http://playground.tensorflow.org) <br>
[TensorBoard: Visualizing Learning](https://www.tensorflow.org/get_started/summaries_and_tensorboard) <br>
[Hands-on TensorBoard (TensorFlow Dev Summit 2017)](https://www.youtube.com/watch?v=eBbEDRsCmv4&feature=youtu.be) <br>
[Machine IDE](https://machineui.co/) <br>
[TensorFlow Mobile](https://www.tensorflow.org/mobile/) <br>
[MobileNets: Open-Source Models for Efficient On-Device Vision](https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html) <br>
[TensorFlow: How to optimise your input pipeline with queues and multi-threading](https://blog.metaflow.fr/tensorflow-how-to-optimise-your-input-pipeline-with-queues-and-multi-threading-e7c3874157e0) <br>
[Exponential decay for learning rate in TF](https://www.tensorflow.org/api_docs/python/tf/train/exponential_decay) <br>
[Monitoring validation loss](https://www.tensorflow.org/api_docs/python/tf/train/SessionRunHook) and [stop hook](https://www.tensorflow.org/api_docs/python/tf/train/StopAtStepHook) and [NaN hook](https://www.tensorflow.org/api_docs/python/tf/train/NanTensorHook) <br>
[Building a Real-Time Object Recognition App with TensorFlow Object Detection API and OpenCV](https://medium.com/towards-data-science/building-a-real-time-object-recognition-app-with-tensorflow-and-opencv-b7a2b4ebdc32) <br>
[Keras as a simplified interface to TensorFlow: tutorial](https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html) <br>
[Introduction to Deep Neural Networks with Keras and Tensorflow](https://github.com/leriomaggio/deep-learning-keras-tensorflow) <br>
[VGG19 and VGG16 on Tensorflow](https://github.com/machrisaa/tensorflow-vgg) <br>

# Datasets #
[COCO-Stuff 10K dataset v1.1](https://github.com/nightrome/cocostuff) <br>
[LiDAR Data for Washington DC is Available as an AWS Public Dataset](https://aws.amazon.com/blogs/publicsector/lidar-data-for-washington-dc-is-available-as-an-aws-public-dataset/) <br>
[The 20BN-JESTER dataset is a large collection of densly-labeled video clips that show humans performing predefinded hand gestures](https://www.twentybn.com/datasets/jester) <br>
[The 20BN-SOMETHING-SOMETHING dataset is a large collection of densly-labeled video clips that show humans performing predefined basic actions with every day objects](https://www.twentybn.com/datasets/something-something) <br>

# Events / meetups #
http://www.london.ai/

# Neural networks #
[Yes you should understand backprop](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b) <br>
[A Step by Step Backpropagation Example](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/) <br>
[What is the difference between test set and validation set?](https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set) <br>
[Learning to Reason with Neural Module Networks](http://bair.berkeley.edu/blog/2017/06/20/learning-to-reason-with-neural-module-networks/) <br>
[An end to end implementation of a Machine Learning pipeline](https://github.com/Spandan-Madan/DeepLearningProject) <br>
[An Overview of Multi-Task Learning in Deep Neural Networks](http://sebastianruder.com/multi-task/) and [Paper](https://arxiv.org/abs/1706.05098) <br>
[SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size](https://arxiv.org/abs/1602.07360) <br>
[Github SqueezeNet: AlexNet-level accuracy with 50x fewer parameters](https://github.com/DeepScale/SqueezeNet) <br>
[PathNet: Evolution Channels Gradient Descent in Super Neural Networks](https://arxiv.org/abs/1701.08734) and [Intro](https://deepmind.com/research/publications/pathnet-evolution-channels-gradient-descent-super-neural-networks/) <br>
[Data Science Bowl 2017 Can you improve lung cancer detection?](https://www.kaggle.com/c/data-science-bowl-2017/) and [Winner solution](https://github.com/lfz/DSB2017), [2nd place](https://juliandewit.github.io/kaggle-ndsb2017/) <br>
[Neural Translation of Musical Style](http://imanmalik.com/cs/2017/06/05/neural-style.html) <br>
[A library for benchmarking vulnerability to adversarial examples](https://github.com/tensorflow/cleverhans) <br>
[Visual Interaction Networks](https://arxiv.org/abs/1706.01433) and [Github](https://github.com/jaesik817/visual-interaction-networks_tensorflow) <br>

# Neural network initialization and hyper-parameters #
[(Xavier initialization) Understanding the difficulty of training deep feedforward neural networks](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf) and [An Explanation of Xavier Initialization](http://andyljones.tumblr.com/post/110998971763/an-explanation-of-xavier-initialization)<br>
[Layer-sequential unit-variance (LSUV) initialization All you need is a good init](https://arxiv.org/abs/1511.06422) [Keras Github](https://github.com/ducha-aiki/LSUV-keras)<br>
[Swish activation](http://arxiv.org/abs/1710.05941) <br>
[(ReLU) Deep Sparse Rectifier Neural Networks](http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf) <br>
[(LRelU) Rectifier Nonlinearities Improve Neural Network Acoustic Models](http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf) <br>
[(PReLU + Xavier for ReLU) Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852) <br>
[(ThresholdedReLU) Zero-bias autoencoders and the benefits of co-adapting features](https://arxiv.org/abs/1402.3337) <br>
[(ELU) Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)](https://arxiv.org/abs/1511.07289) <br>
[(SELU) Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515), [Github](https://github.com/bioinf-jku/SNNs) + [Github research](https://gist.github.com/eamartin/d7f1f71e5ce54112fe05e2f2f17ebedf/revisions) and [Reddit](https://www.reddit.com/r/MachineLearning/comments/6g5tg1/r_selfnormalizing_neural_networks_improved_elu/)<br>
[(CReLu) Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units](https://arxiv.org/abs/1603.05201) <br>
[Compare distribution of SELU, ReLU, LReLU and other activation functions](https://github.com/shaohua0116/Activation-Visualization-Histogram) and [Evaluation on ImageNet-2012](https://github.com/ducha-aiki/caffenet-benchmark/blob/master/Activations.md) <br>
[A Simple Way to Initialize Recurrent Networks of Rectified Linear Units](https://arxiv.org/abs/1504.00941) <br>
[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167) and [comments](https://gist.github.com/shagunsodhani/4441216a298df0fe6ab0) <br>
[Understanding the backward pass through Batch Normalization Layer](https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html) <br>
[Initialization of deep networks](http://deepdish.io/2015/02/24/network-initialization/) <br>
[Practical recommendations for gradient-based training of deep architectures](https://arxiv.org/abs/1206.5533) <br>
[Efficient BackProp by Yann LeCun](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf) <br>
[Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning](https://arxiv.org/abs/1506.02142) <br>
[Improving neural networks by preventing co-adaptation of feature detectors](https://arxiv.org/abs/1207.0580) <br>
[Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf) <br>
[Why dropouts prevent overfitting in Deep Neural Networks](https://medium.com/@vivek.yadav/why-dropouts-prevent-overfitting-in-deep-neural-networks-937e2543a701) <br>
[Concrete Dropout](https://arxiv.org/abs/1705.07832) and [Github](https://github.com/yaringal/ConcreteDropout) <br>
[Hyperparameter optimization for Neural Networks](http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html) <br>
[The Marginal Value of Adaptive Gradient Methods in Machine Learning](https://arxiv.org/abs/1705.08292) <br>
[YellowFin: An automatic tuner for momentum SGD](https://cs.stanford.edu/~zjian/project/YellowFin/) and [Github](https://github.com/JianGoForIt/YellowFin) <br>
[Tips for Training Recurrent Neural Networks](http://danijar.com/tips-for-training-recurrent-neural-networks/) <br>
[Must Know Tips/Tricks in Deep Neural Networks (by Xiu-Shen Wei)](http://lamda.nju.edu.cn/weixs/project/CNNTricks/CNNTricks.html) <br>
[The Black Magic of Deep Learning - Tips and Tricks for the practitioner](https://nmarkou.blogspot.de/2017/02/the-black-magic-of-deep-learning-tips.html) <br>
[Deep Learning workshop - Chapter 11 Practical Methodology](https://docs.google.com/presentation/d/171B4swM4qcx64QAIgqJ2t0ZtvKWZdaFFDy6ZI_oIoS8/edit#slide=id.p), [Video 1](https://www.youtube.com/watch?v=wMivFBFWHWE&feature=youtu.be), [Video 2](https://www.youtube.com/watch?v=GGUmjFPN77Q&feature=youtu.be) <br>
[Snapshot Ensembles: Train 1, get M for free](https://arxiv.org/abs/1704.00109) <br>
[FreezeOut: Accelerate Training by Progressively Freezing Layers](https://arxiv.org/abs/1706.04983) <br>
[Train your deep model faster and sharper — two novel techniques](https://hackernoon.com/training-your-deep-model-faster-and-sharper-e85076c3b047) <br>
[Hyperopt – Finding the optimal hyper parameters](https://johnflux.com/2017/02/10/python-hyperopt-finding-the-optimal-hyper-parameters/) <br>
[Hyperopt tutorial for Optimizing Neural Networks’ Hyperparameters](http://vooban.com/en/tips-articles-geek-stuff/hyperopt-tutorial-for-optimizing-neural-networks-hyperparameters/)<br>
[How to use cross-validation in predictive modeling](http://stuartlacy.co.uk/04022016-crossvalidation)<br>
[(Convolution resize vs deconv)Deconvolution and Checkerboard Artifacts](http://distill.pub/2016/deconv-checkerboard/) <br>

# Network optimization algorithms #
[An overview of gradient descent optimization algorithms](http://sebastianruder.com/optimizing-gradient-descent/index.html) <br>
[Why Momentum Really Works](http://distill.pub/2017/momentum/) <br>
[Gentle Introduction to the Adam Optimization Algorithm for Deep Learning](http://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) <br>
[How to Escape Saddle Points Efficiently](http://www.offconvex.org/2017/07/19/saddle-efficiency/) and [Paper](https://arxiv.org/abs/1703.00887) <br>
[1-Bit Stochastic Gradient Descent and its Application to Data-Parallel Distributed Training of Speech DNNs](https://www.microsoft.com/en-us/research/publication/1-bit-stochastic-gradient-descent-and-application-to-data-parallel-distributed-training-of-speech-dnns/) <br>

# Neural Network visualization #
[Facebook Visdom](https://github.com/facebookresearch/visdom) <br>
[Picasso: A free open-source visualizer for Convolutional Neural Networks](https://medium.com/merantix/picasso-a-free-open-source-visualizer-for-cnns-d8ed3a35cfc5) and [Github](https://github.com/merantix/picasso) <br>
[How to Visualize Your Recurrent Neural Network with Attention in Keras](https://medium.com/datalogue/attention-in-keras-1892773a4f22) <br>
[Visualizing MNIST: An Exploration of Dimensionality Reduction](https://colah.github.io/posts/2014-10-Visualizing-MNIST/) <br>
[How to Use t-SNE Effectively](http://distill.pub/2016/misread-tsne/) <br>
[Understanding Deep Image Representations by Inverting Them](https://arxiv.org/abs/1412.0035) <br>

# CNN (Convolution Neural Networks) #
[Systematic evaluation of CNN advances on the ImageNet](https://arxiv.org/abs/1606.02228) <br>
[9 Key Deep Learning Papers, Explained](http://www.kdnuggets.com/2016/09/9-key-deep-learning-papers-explained.html) <br>
[CS231n CNN intro](https://cs231n.github.io/neural-networks-1/) <br>
[Deep Learning #3: More on CNNs & Handling Overfitting](https://medium.com/towards-data-science/deep-learning-3-more-on-cnns-handling-overfitting-2bd5d99abe5d) <br>
[Transfer Learning from CS231n](https://cs231n.github.io/transfer-learning/) <br>
[What is Transfer Learning? by Sebastian Ruder](http://sebastianruder.com/transfer-learning/index.html) <br>
[Network Dissection: Quantifying Interpretability of Deep Visual Representations](http://netdissect.csail.mit.edu/) and [Github](https://github.com/CSAILVision/NetDissect) <br>
[(Mean-Max Pooling) Dual Path Networks](https://arxiv.org/abs/1707.01629) and [Github](https://github.com/cypw/DPNs)<br>
[Deconvolutional Networks](http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf) <br>
[What are deconvolutional layers?](https://datascience.stackexchange.com/questions/6107/what-are-deconvolutional-layers) <br>
[Convolution arithmetic tutorial](http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html) <br>
[Architecture of Convolutional Neural Networks (CNNs) demystified](https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/) <br>
[Densely Connected Convolutional Networks](https://arxiv.org/abs/1608.06993) and [Github](https://github.com/liuzhuang13/DenseNet)<br>
[Convolutional Methods for Text](https://medium.com/@TalPerry/convolutional-methods-for-text-d5260fd5675f)
[Interpreting neurons in an LSTM network](https://yerevann.github.io/2017/06/27/interpreting-neurons-in-an-LSTM-network/) <br>
[Wide Residual Networks](https://arxiv.org/abs/1605.07146), [Github](https://github.com/szagoruyko/wide-residual-networks), [Keras version](https://github.com/titu1994/Wide-Residual-Networks/) <br>
[Using 3D Convolutional Neural Networks for Speaker Verification](https://arxiv.org/abs/1705.09422) and [Github](https://github.com/astorfi/3D-convolutional-speaker-recognition) <br>
[A simple neural network module for relational reasoning](https://arxiv.org/abs/1706.01427) [Github Keras](https://github.com/Alan-Lee123/relation-network) [Github Pytorch](https://github.com/kimhc6028/relational-networks)<br>
[Gesture recognition via CNN. Implemented in Keras + Theano + OpenCV](https://github.com/asingh33/CNNGestureRecognizer) <br>
[Meta-Learning with Temporal Convolutions](https://arxiv.org/abs/1707.03141) <br>

# RNN (Recurrent Neural Networks) #
[Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling](https://arxiv.org/abs/1412.3555) <br>
[An Empirical Exploration of Recurrent Network Architectures](http://proceedings.mlr.press/v37/jozefowicz15.pdf) <br>
[Visualizing and Understanding Recurrent Networks](https://arxiv.org/abs/1506.02078) <br>
[Video - Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM)](https://www.youtube.com/watch?v=WCUNPb-5EYI) <br>
[Performance RNN: Generating Music with Expressive Timing and Dynamics](https://magenta.tensorflow.org/performance-rnn) <br>
[Recurrent Additive Networks](http://www.kentonl.com/pub/llz.2017.pdf) <br>
[Attention and Augmented Recurrent Neural Networks](http://distill.pub/2016/augmented-rnns/) <br>
[Human activity recognition using TensorFlow on smartphone sensors dataset and an LSTM RNN](https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition) <br>

# Image processing #
[COCO-Stuff dataset](https://arxiv.org/abs/1612.03716) and [Github](https://github.com/nightrome/cocostuff) <br>
[Show and Tell: A Neural Image Caption Generator](https://arxiv.org/abs/1411.4555) <br>
[DRAW: A Recurrent Neural Network For Image Generation](https://arxiv.org/abs/1502.04623) <br>
[Colorful Image Colorization](https://richzhang.github.io/colorization/) <br>

# Image style transfer #
[Introduction to Style Transfer from fast.ai](http://course.fast.ai/lessons/lesson8.html) <br>
[Using other neural models for style transfer](https://github.com/jcjohnson/neural-style/wiki/Using-Other-Neural-Models) <br>
[Picking an optimizer for Style Transfer](https://blog.slavv.com/picking-an-optimizer-for-style-transfer-86e7b8cba84b) <br>

| Paper | Comment |
| --- | --- |
| [A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576) | Original L. Gatys paper |
| [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/abs/1603.08155) | Work of Standford team to train neural net that would be able to estimate 1 specific artistic style |
| [Instance Normalization: The Missing Ingredient for Fast Stylization](https://arxiv.org/abs/1607.08022) | Follow-up on Stanford team paper that improved it by introducing Instance Normalization |
| [A Learned Representation For Artistic Style](https://arxiv.org/abs/1610.07629) | Introduced ability to learn multipe styles by 1 neural net using Conditional Instance Normalization |
| [Preserving Color in Neural Artistic Style Transfer](http://arxiv.org/abs/1606.05897) | Transfer style, but preserve original colors |
| [Deep Photo Style Transfer](http://arxiv.org/abs/1703.07511) | Photorealistic style transfer | 
| [Demystifying Neural Style Transfer](http://arxiv.org/abs/1701.01036) | Provided math, explaining that Gram matrices is equivalent to minimize the Maximum Mean Discrepancy (MMD) and new methods for style transfer |
| [Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization](http://arxiv.org/abs/1703.06868) | Transfer arbitary style to new image without pre-learning it |
| [Neural Style Transfer: A Review](http://arxiv.org/abs/1705.04058) <br> [Github repository](https://github.com/ycjing/Neural-Style-Transfer-Papers) <br> | Overview of major papers in area of style transfer |  
| [Artistic style transfer for videos](https://arxiv.org/abs/1604.08610) and [Torch implementation](https://github.com/manuelruder/artistic-videos)<br> | Paper that proposed approach for solving issues related to style transfer to video content |

# Image Object and Semantic segmentation #
[Semantic Segmentation using Fully Convolutional Networks over the years](https://meetshah1995.github.io/semantic-segmentation/deep-learning/pytorch/visdom/2017/06/01/semantic-segmentation-over-the-years.html) <br>
[A list of all papers on Semantic Segmentation and the datasets they use](https://github.com/nightrome/really-awesome-semantic-segmentation) <br>
[ENet: A Deep Neural Network Architecture for Real-Time Semantic Segmentation](https://arxiv.org/abs/1606.02147) and [Github](https://github.com/kwotsin/TensorFlow-ENet) <br>
[Deep Learning for Photo Editing](https://blog.photoeditorsdk.com/deep-learning-for-photo-editing-943bdf9765e1) <br>
[Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556) <br>
[The "something something" video database for learning and evaluating visual common sense](https://arxiv.org/abs/1706.04261) <br>
[DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling](https://arxiv.org/abs/1703.10295) <br>
[Object-Extent Pooling for Weakly Supervised Single-Shot Localization](https://arxiv.org/abs/1707.06180) <br>
[The Devil is in the Decoder](https://arxiv.org/abs/1707.05847) <br>
[YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242) <br>
[Annotating Object Instances with a Polygon-RNN](https://arxiv.org/abs/1704.05548) <br>
[The More You Know: Using Knowledge Graphs for Image Classification](https://arxiv.org/abs/1612.04844) <br>

# NMT (Neural Machine Translation) #
[Neural Machine Translation (seq2seq) Tutorial](https://github.com/tensorflow/nmt) and [Intro](https://research.googleblog.com/2017/07/building-your-own-neural-machine.html) <br>
[Massive Exploration of Neural Machine Translation Architectures](https://arxiv.org/abs/1506.02078) <br>
[Neural Machine Translation in Linear Time](https://arxiv.org/abs/1610.10099)
[Introduction to Neural Machine Translation with GPUs (part 1)](https://devblogs.nvidia.com/parallelforall/introduction-neural-machine-translation-with-gpus/) <br>
[On the State of the Art of Evaluation in Neural Language Models](https://arxiv.org/abs/1707.05589) <br>

# seq2seq (Sequence to sequence) #
[Introduction to pointer networks](http://fastml.com/introduction-to-pointer-networks) <br>
[Video Sequence to Sequence Deep Learning (Quoc Le, Google)](https://www.youtube.com/watch?v=G5RY_SUJih4) <br>
[TensorFlow Sequence-to-Sequence Models](https://www.tensorflow.org/tutorials/seq2seq) <br>
[Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215) <br>
[Introducing tf-seq2seq: An Open Source Sequence-to-Sequence Framework in TensorFlow](https://research.googleblog.com/2017/04/introducing-tf-seq2seq-open-source.html?m=1) <br>
[Dynamic seq2seq in TensorFlow, step by step](https://github.com/ematvey/tensorflow-seq2seq-tutorials) <br>
[A neural chatbot using sequence to sequence model with attentional decoder](https://github.com/chiphuyen/tf-stanford-tutorials/tree/master/assignments/chatbot)
[Deep Learning for Chatbots, Part 1 – Introduction](http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/) <br>
[SEQUENCE-TO-SEQUENCE RNNS FOR TEXT SUMMARIZATION](https://pdfs.semanticscholar.org/3fbc/45152f20403266b02c4c2adab26fb367522d.pdf) <br>

# NLP #
[Multi-Scale Context Aggregation by Dilated Convolutions](https://arxiv.org/abs/1511.07122) <br>
[The Definitive Guide to Natural Language Processing](https://monkeylearn.com/blog/the-definitive-guide-to-natural-language-processing/) <br>
[Ultimate Guide to Understand & Implement Natural Language Processing (with codes in Python)](https://www.analyticsvidhya.com/blog/2017/01/ultimate-guide-to-understand-implement-natural-language-processing-codes-in-python/) <br>
[Attention and Memory in Deep Learning and NLP](http://www.wildml.com/2016/01/attention-and-memory-in-deep-learning-and-nlp/) <br>
[Stanford Named Entity Recognizer (NER)](https://nlp.stanford.edu/software/CRF-NER.shtml) <br>
[OpenNMT An open-source neural machine translation system](http://opennmt.net/) <br>
[Text summarization with TensorFlow](https://research.googleblog.com/2016/08/text-summarization-with-tensorflow.html) <br>
[Generating Sentences from a Continuous Space](https://arxiv.org/abs/1511.06349) <br>
[Code for "How to Make a Text Summarizer - Intro to Deep Learning #10" by Siraj Raval on Youtube](https://github.com/llSourcell/How_to_make_a_text_summarizer) <br>
[Recurrent Neural Networks with Word Embeddings](http://deeplearning.net/tutorial/rnnslu.html) <br>
[Text Generation With LSTM Recurrent Neural Networks in Python with Keras](http://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/) <br>
[Has Deep Learning been applied to automatic text summarization (successfully)?](https://www.quora.com/Has-Deep-Learning-been-applied-to-automatic-text-summarization-successfully) <br>
[Text Clustering: Get quick insights from Unstructured Data](http://www.datasciencecentral.com/profiles/blog/show?id=6448529%3ABlogPost%3A585609) <br>
[Natural Language Processing with Deep Learning is almost human-level accurate. Worse yet, it gets smart!](https://sigmoidal.io/boosting-your-solutions-with-nlp/) <br>
[State-of-the-art neural coreference resolution for chatbots](https://medium.com/huggingface/state-of-the-art-neural-coreference-resolution-for-chatbots-3302365dcf30), [Github](https://github.com/huggingface/neuralcoref) and [Paper](http://cs.stanford.edu/people/kevclark/resources/clark-manning-emnlp2016-deep.pdf) <br>
[Embed, encode, attend, predict: The new deep learning formula for state-of-the-art NLP models](https://explosion.ai/blog/deep-learning-formula-nlp) <br>

# Word embeddings #
[Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) <br>
[Distributed Representations of Words and Phrases and their Compositionality](https://arxiv.org/abs/1310.4546) <br>
[Original code for word2vec paper with comments](https://github.com/chrisjmccormick/word2vec_commented) <br>
[word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method](https://arxiv.org/abs/1402.3722) <br>
[Deep Learning, NLP, and Representations](https://colah.github.io/posts/2014-07-NLP-RNNs-Representations/) <br>
[Understanding vector representations](https://www.samtalksml.net/from-linear-regression-to-vector-representations/) <br>
[Demystifying Word2Vec](http://www.deeplearningweekly.com/blog/demystifying-word2vec) <br>
[TensorFlow Vector Representations of Words](https://www.tensorflow.org/tutorials/word2vec) <br>
[Word2Vec Tutorial - The Skip-Gram Model](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/) and [Pdf](http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_I_The_Skip-Gram_Model.pdf)<br>
[Word2Vec Tutorial Part 2 - Negative Sampling](http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/) and [Pdf](http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_II_The_Continuous_Bag-of-Words_Model.pdf)<br>
[Word2Vec Resources](http://mccormickml.com/2016/04/27/word2vec-resources/) <br>
[Word2Vec (Part 1): NLP With Deep Learning with Tensorflow (Skip-gram)](http://www.thushv.com/natural_language_processing/word2vec-part-1-nlp-with-deep-learning-with-tensorflow-skip-gram/) <br>
[Word2Vec (Part 2): NLP With Deep Learning with Tensorflow (CBOW)](http://www.thushv.com/natural_language_processing/word2vec-part-2-nlp-with-deep-learning-with-tensorflow-cbow/) <br>
[Word2Vec test dataset](http://mattmahoney.net/dc/text8.zip) <br>
[Pretrained Character Embeddings for Deep Learning and Automatic Text Generation](http://minimaxir.com/2017/04/char-embeddings/) <br>
[Kaggle Bag of Words Meets Bags of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial) <br>
[fairseq Facebook AI Research Sequence-to-Sequence Toolkit](https://github.com/facebookresearch/fairseq) <br>
[GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/projects/glove/) <br>
[GloVe: Global Vectors for Word Representation + Implementation](http://www.thushv.com/natural_language_processing/glove-global-vectors-for-word-representation/) <br>
[Learning when to skim and when to read](https://einstein.ai/research/learning-when-to-skim-and-when-to-read) <br>
[Swivel: Improving Embeddings by Noticing What's Missing](https://arxiv.org/abs/1602.02215) <br>
[Swivel in Tensorflow](https://github.com/tensorflow/models/tree/master/swivel) <br>
[Item2Vec: Neural Item Embedding for Collaborative Filtering](https://arxiv.org/abs/1603.04259) <br>
[How to Generate a Good Word Embedding?](https://arxiv.org/abs/1507.05523) <br>
[Enriching Word Vectors with Subword Information](https://arxiv.org/abs/1607.04606) <br>
[Pre-trained word vectors for 294 languages (fastText) from Facebook](https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md) <br>
[Aligning vector representations](https://www.samtalksml.net/aligning-vector-representations/) <br>
[Aligning the fastText vectors of 78 languages](https://github.com/Babylonpartners/fastText_multilingual) <br>
[Offline bilingual word vectors, orthogonal transformations and the inverted softmax](https://arxiv.org/abs/1702.03859) <br>
[ParlAI: A new software platform for dialog research](https://code.facebook.com/posts/266433647155520/parlai-a-new-software-platform-for-dialog-research/) <br>
[Supervised Learning of Universal Sentence Representations from Natural Language Inference Data](https://arxiv.org/abs/1705.02364) and [Github](https://github.com/facebookresearch/InferSent) <br>
[SentEval - A python tool for evaluating the quality of sentence embeddings](https://github.com/facebookresearch/SentEval)<br>

# Sentiment analysis #
[Unsupervised Sentiment Neuron](https://blog.openai.com/unsupervised-sentiment-neuron/) <br>
[Generative and Discriminative Text Classification with Recurrent Neural Networks](https://arxiv.org/abs/1703.01898) <br>

# Audio #
[Neural Speech Recognizer: Acoustic-to-Word LSTM Model for Large Vocabulary Speech Recognition](https://arxiv.org/abs/1610.09975) <br>
[Speech Recognition with Deep Recurrent Neural Networks](https://arxiv.org/abs/1303.5778) <br>
[WaveNet: A Generative Model for Raw Audio](https://deepmind.com/blog/wavenet-generative-model-raw-audio/), [Paper](https://arxiv.org/abs/1609.03499) <br>
[Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders](https://arxiv.org/abs/1704.01279) [Github](https://github.com/tensorflow/magenta/tree/master/magenta/models/nsynth) and [Intro](https://magenta.tensorflow.org/nsynth) <br>

# GANs (General Adversarial Networks) #
[Generative Adversarial Networks - nVidia GPU Tech conference 2017 intro](http://on-demand.gputechconf.com/gtc/2017/video/s7502-ian-goodfellow-generative-adversarial-networks.mp4) <br>
[A list of GAN papers](https://github.com/nightrome/really-awesome-gan) <br>
[Collection of generative models in Tensorflow](https://github.com/hwalsuklee/tensorflow-generative-model-collections) <br>
[Deep Learning Research Review Week 1: Generative Adversarial Nets](https://opendatascience.com/blog/deep-learning-research-review-week-1-generative-adversarial-nets/) <br>
[Deep Learning with cats](https://github.com/AlexiaJM/Deep-learning-with-cats) <br>
[CAN: Creative Adversarial Networks, Generating "Art" by Learning About Styles and Deviating from Style Norms](https://arxiv.org/abs/1706.07068) <br>
[PixelGAN Autoencoders](https://arxiv.org/abs/1706.00531) <br>
[Do GANs actually learn the distribution? An empirical study](https://arxiv.org/abs/1706.08224) <br>
[Keras implementation of the Conditional GAN](https://github.com/r0nn13/conditional-dcgan-keras) <br>
[Fantastic GANs and where to find them](http://guimperarnau.com/blog/2017/03/Fantastic-GANs-and-where-to-find-them) <br>

# Autoencoders #
[Автоэнкодеры в Keras](https://habrahabr.ru/post/331382/) <br>
[Using Deep Learning to Reconstruct High-Resolution Audio](https://blog.insightdatascience.com/using-deep-learning-to-reconstruct-high-resolution-audio-29deee8b7ccd) <br>
["Training Deep AutoEncoders for Collaborative Filtering"](https://github.com/NVIDIA/DeepRecommender) <br>

# One-shot learning #
[One-shot Learning with Memory-Augmented Neural Networks](https://arxiv.org/abs/1605.06065) + [Explanation](https://rylanschaeffer.github.io/content/research/one_shot_learning_with_memory_augmented_nn/main.html)
[Video Active One-shot Learning](https://www.youtube.com/watch?v=CzQSQ_0Z-QU) <br>
[Differential neural computer from DeepMind and more advances in backward propagation](https://futuristech.info/posts/differential-neural-computer-from-deepmind-and-more-advances-in-backward-propagation) <br>
[Google’s DeepMind AI Now Capable of ‘Deep Neural Reasoning’](https://thenewstack.io/googles-deepmind-ai-now-capable-deep-neural-reasoning/) <br>
[This is the code for "How to Learn from Little Data - Intro to Deep Learning #17' by Siraj Raval on YouTube](https://github.com/llSourcell/How-to-Learn-from-Little-Data) <br>

# Papers #
| Name | Code | Comments |
| --- | --- | --- |
| [Variational Graph Auto-Encoders](https://arxiv.org/abs/1611.07308) | https://github.com/tkipf/gae | |
| [A Long Short-Term Memory Model for Answer Sentence Selection in Question Answering](http://www.aclweb.org/anthology/P15-2116) | |
| [Learning to act by predicting the future](https://openreview.net/forum?id=rJLS7qKel) | https://blog.acolyer.org/2017/05/12/learning-to-act-by-predicting-the-future/ | |
| [Deep Interest Network for Click-Through Rate Prediction](https://arxiv.org/abs/1706.06978) | |


# Self-driving cars #
[In-Depth on Udacity’s Self-Driving Car Curriculum](https://medium.com/self-driving-cars/term-1-in-depth-on-udacitys-self-driving-car-curriculum-ffcf46af0c08) <br>
[Term 2: In-Depth on Udacity’s Self-Driving Car Curriculum](https://medium.com/udacity/term-2-in-depth-on-udacitys-self-driving-car-curriculum-775130aae502) <br>
[Term 3: In-Depth on Udacity’s Self-Driving Car Curriculum](https://medium.com/udacity/term-3-in-depth-on-udacitys-self-driving-car-curriculum-15d03e45d7ea) <br>
[The Secrets of Term 3 Revealed!](https://medium.com/udacity/the-secrets-of-term-3-revealed-216e0cb11a42) <br>
[Udacity Self-Driving Car Project Q&As](https://www.youtube.com/playlist?list=PLAwxTw4SYaPkz3HerxrHlu1Seq8ZA7-5P) <br>
Udacity Self-Driving car preparation: [Essence of linear algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab), [Derivatives of multivariable functions](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives) <br>
[nVidia End-to-End Deep Learning for Self-Driving Cars](https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/) <br>
[Video Amnon Shashua CVPR 2016 keynote: Autonomous Driving, Computer Vision and Machine Learning](https://www.youtube.com/watch?v=n8T7A3wqH3Q) <br>
[Multi-Scale Context Aggregation by Dilated Convolutions](https://arxiv.org/abs/1511.07122) and [TF Github](https://github.com/ndrplz/dilation-tensorflow) <br>
[An augmentation based deep neural network approach to learn human driving behavior](https://chatbotslife.com/using-augmentation-to-mimic-human-driving-496b569760a9) <br>
[An Introduction to LIDAR: The Key Self-Driving Car Sensor](https://news.voyage.auto/an-introduction-to-lidar-the-key-self-driving-car-sensor-a7e405590cff) <br>
[An Introduction to the CAN Bus: How to Programmatically Control a Car](https://news.voyage.auto/an-introduction-to-the-can-bus-how-to-programmatically-control-a-car-f1b18be4f377) <br>
[A Comparison of Self-Driving Sensors](https://medium.com/self-driving-cars/a-comparison-of-self-driving-sensors-2bb7702a85af) <br>
[Under the Hood of a Self-Driving Taxi](https://news.voyage.auto/under-the-hood-of-a-self-driving-car-78e8bbce62a6) <br>
[Vehicle Detection and Tracking](https://medium.com/towards-data-science/vehicle-detection-and-tracking-44b851d70508) <br>
[How do self driving cars drive? Part 1: Lane keeping assist](https://medium.com/@edersantana/how-do-self-driving-cars-drive-part-1-lane-keeping-assist-581f6ff50349) <br>
[Hacking my own car: Lessons learnt after a few months of setbacks.](https://medium.com/@autti/hacking-my-own-car-lessons-learn-after-a-few-months-of-setbacks-76b555d28d1b) <br>
[How do self driving cars drive? Part 1: Lane keeping assist](https://medium.com/@edersantana/how-do-self-driving-cars-drive-part-1-lane-keeping-assist-581f6ff50349) <br>
[3 Approaches to Vehicle Detection and Tracking](https://medium.com/self-driving-cars/3-approaches-to-vehicle-detection-and-tracking-413fe50f75fc) <br>
[Visual Object Tracking using Adaptive Correlation Filters](http://www.cs.colostate.edu/~draper/papers/bolme_cvpr10.pdf) <br>
[Visualizing lidar data](https://navoshta.com/kitti-lidar/) <br>
[Udacity Students Past, Present, and Future](https://medium.com/self-driving-cars/udacity-students-past-present-and-future-6f9beacb3206) <br>
[Youtube lectures on Kalman Filter](https://www.youtube.com/playlist?list=PLX2gX-ftPVXU3oUFNATxGXY90AULiqnWT) <br>
[Youtube lectures on Model predictive control](https://www.youtube.com/playlist?list=PLs7mcKy_nInFEpygo_VrqDFCsQVnGaoy-) <br>
[Youtube Controlling Self Driving Cars](https://www.youtube.com/watch?v=4Y7zG48uHRo) <br>
[Autoware](https://github.com/CPFL/Autoware) <br>
[Robot Operating System (ROS)](http://www.ros.org/) <br>
[Baidu Apollo](http://apollo.auto) and [Github](https://github.com/ApolloAuto/apollo) <br>
[Open Source Self Driving Car Initiative](https://github.com/OSSDC) <br>
[Elcano Project autonomous driving for tricycles and like](http://www.elcanoproject.org/) <br>
[SELF RACING CARS](http://selfracingcars.com/)<br>
[Book The Science of Vehicle Dynamics: Handling, Braking, and Ride of Road and Race Cars](https://www.amazon.com/Science-Vehicle-Dynamics-Handling-Braking/dp/9401785325/) <br>
[comma.ai Our Road to Self Driving Victory](https://medium.com/@comma_ai/our-road-to-self-driving-victory-603a9ed20204) <br>
[A panda and a cabana: How to get started car hacking with comma.ai](https://medium.com/@comma_ai/a-panda-and-a-cabana-how-to-get-started-car-hacking-with-comma-ai-b5e46fae8646) <br>
[Stanford Code From Cars That Entered DARPA Grand Challenges](https://github.com/emmjaykay/stanford_self_driving_car_code) <br>
[BERKELEY AUTONOMOUS RACE CAR](http://www.barc-project.com/) <br>
[Self Driving RC Car](https://zhengludwig.wordpress.com/projects/self-driving-rc-car/) <br>
[OpenCV Python Neural Network Autonomous RC Car](https://github.com/hamuchiwa/AutoRCCar) <br>
[Build Your Own Android-Powered Self Driving R/C Car](http://makezine.com/projects/build-android-powered-autonomous-rc-car/) and [Github](https://github.com/platisd/AndroidCar) <br>
[Arduino Powered Autonomous Vehicle](http://www.instructables.com/id/Arduino-Powered-Autonomous-Vehicle/) <br>
[Autonomous Control of RC Car Using Arduino](http://www.instructables.com/id/Autonomous-Control-of-RC-Car-Using-Arduino/) <br>
[40 Excellent Autonomous Mobile Robots on Wheels That You Can Build at Home](https://www.intorobotics.com/40-excellent-autonomous-mobile-robots-on-wheels-that-you-can-build-at-home/) <br>
[Using reinforcement learning in Python to teach a virtual car to avoid obstacles](https://medium.com/@harvitronix/using-reinforcement-learning-in-python-to-teach-a-virtual-car-to-avoid-obstacles-6e782cc7d4c6), [Part 2](https://medium.com/@harvitronix/reinforcement-learning-in-python-to-teach-a-virtual-car-to-avoid-obstacles-part-2-93e614fcd238), [Part 3](https://medium.com/@harvitronix/reinforcement-learning-in-python-to-teach-an-rc-car-to-avoid-obstacles-part-3-a1d063ac962f), [Github](https://github.com/harvitronix/reinforcement-learning-car) <br>
[The Race to 2021: The State of Autonomous Vehicles and a "Who's Who" of Industry Drivers](https://www.slideshare.net/Altimeter/the-race-to-2021-the-state-of-autonomous-vehicles-and-a-whos-who-of-industry-drivers) <br>
[Becoming a Self-Driving Car & Machine Learning Engineer](https://medium.com/udacity/becoming-a-self-driving-car-machine-learning-engineer-4f9433e49c19) <br>
[Quora How do I get a job working on autonomous or self-driving cars?](https://www.quora.com/How-do-I-get-a-job-working-on-autonomous-or-self-driving-cars) <br>
[Quora How can one learn to be a self driving car engineer?](https://www.quora.com/How-can-one-learn-to-be-a-self-driving-car-engineer) <br>
[The Open Source Car Control Project ](https://github.com/PolySync/OSCC) <br>

# Reinforcement Learning #
[Deep Reinforcement Learning: Pong from Pixels](https://karpathy.github.io/2016/05/31/rl/) <br>
[Minimal and Clean Reinforcement Learning Examples](https://github.com/rlcode/reinforcement-learning) <br>
[DEMYSTIFYING DEEP REINFORCEMENT LEARNING](http://neuro.cs.ut.ee/demystifying-deep-reinforcement-learning/) <br>
[Simple Reinforcement Learning article series](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0) <br>
[Noisy Networks for Exploration](https://arxiv.org/abs/1706.10295) <br>
[Trust Region Policy Optimization](https://arxiv.org/abs/1502.05477) <br>
[Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347), [Github](https://github.com/openai/baselines) and [Intro](https://blog.openai.com/openai-baselines-ppo/) <br>

# Robotics #
[Faster Physics in Python from OpenAI](https://blog.openai.com/faster-robot-simulation-in-python/) <br>
[Robots that Learn](https://blog.openai.com/robots-that-learn/) <br>
[Releasing the Dexterity Network (Dex-Net) 2.0 Dataset for Deep Grasping](http://bair.berkeley.edu/blog/2017/06/27/dexnet-2.0/) <br>
[Drone Uses AI and 11,500 Crashes to Learn How to Fly](http://spectrum.ieee.org/automaton/robotics/drones/drone-uses-ai-and-11500-crashes-to-learn-how-to-fly) <br>
[AIY Projects: Do-it-yourself AI for Makers](https://aiyprojects.withgoogle.com/voice/) and [Intro](https://developers.googleblog.com/2017/05/aiy-projects-voice-kit.html) <br>
[A Raspberry Pi Hexy — Transcript](https://medium.com/@mithi/a-raspberry-pi-hexy-transcript-62533c69a566) <br>

# Misc #
[All the slides (and more) from the 2017 IA Summit](https://medium.com/@IAsummit/all-the-slides-and-more-from-the-2017-ia-summit-30b37f95e74e) <br>
https://medium.com/intuitionmachine/navigating-the-unsupervised-learning-landscape-951bd5842df9 <br>
https://blog.twitter.com/engineering/en_us/topics/insights/2017/using-deep-learning-at-scale-in-twitters-timelines.html <br>

# Conference videos #
[ICCV17](https://www.youtube.com/channel/UC0n76gicaarsN_Y9YShWwhw/playlists) <br>
[NIPS 2017](https://www.facebook.com/pg/nipsfoundation/videos/) <br>
